{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db370b50-2abe-4e70-98e3-6fce1b89ed76",
   "metadata": {},
   "source": [
    "# Training_Classification_Model_VGG19_on_custom_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb5250-bbcd-4779-9fab-392cfa26cd94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install essential libraries # OS is python's standard library. So no need to download it.\n",
    "\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install opencv-python        \n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b5113-f8ea-4668-bc86-38364ad132c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccfbb3c-c899-48a2-9bb0-b4d685257e45",
   "metadata": {},
   "source": [
    "# Images Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c0960-6611-4088-b861-9377f55e904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 model inputs are color images of dimensions 224Ã—224 (resizing is required)\n",
    "\n",
    "# Setting the paths of the Dataset\n",
    "train_path = \"../Classification_Custom_Dataset/train\"\n",
    "test_path = \"../Classification_Custom_Dataset/test\"\n",
    "val_path = \"../Classification_Custom_Dataset/val\"\n",
    "\n",
    "# Getting the images of the training set\n",
    "x_train=[]\n",
    "\n",
    "#The os.listdir() method in Python is used to get the list of all files and directories in the specified directory. \n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "    sub_path = train_path+\"/\"+folder\n",
    "    #print(sub_path)\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path = sub_path+\"/\"+img\n",
    "        #print(image_path)\n",
    "        img_arr = cv2.imread(image_path)\n",
    "        img_arr = cv2.resize(img_arr,(224,224))\n",
    "        x_train.append(img_arr)\n",
    "        \n",
    "\n",
    "# Getting the images of the testing set\n",
    "x_test=[]\n",
    "for folder in os.listdir(test_path):\n",
    "    sub_path = test_path+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path = sub_path+\"/\"+img\n",
    "        img_arr = cv2.imread(image_path)\n",
    "        img_arr = cv2.resize(img_arr,(224,224))\n",
    "        x_test.append(img_arr)\n",
    "\n",
    "\n",
    "# Getting the images of the validation set\n",
    "x_val=[]\n",
    "for folder in os.listdir(val_path):\n",
    "    sub_path = val_path+\"/\"+folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path = sub_path+\"/\"+img\n",
    "        img_arr = cv2.imread(image_path)\n",
    "        img_arr = cv2.resize(img_arr,(224,224))\n",
    "        x_val.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2c8e2-87a9-4d7b-a394-22b7ae4cc9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting x_train, x_test, and x_val into Numpy arrays\n",
    "\n",
    "train_x = np.array(x_train)\n",
    "test_x = np.array(x_test)\n",
    "val_x = np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f167d0-772f-412d-8f71-6cb9440d1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divided by 255.0 for normalization.\n",
    "# By dividing an image by 255 to rescale the image from 0-255 to 0-1.\n",
    "\n",
    "train_x = train_x/255.0\n",
    "test_x = test_x/255.0\n",
    "val_x = val_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7dbf7-3c55-43f6-bdc6-6f39480cf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ImageDataGenerator to compute the labels of the corresponding datasets.\n",
    "# We must walk through the folders and find out the corresponding labels of the images stored here.\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')\n",
    "val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719869e-60e1-4930-abac-4280d2140dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the classes to train_y, test_y, and val_y\n",
    "# where the label of the image train_x[i] is train_y[i]\n",
    "\n",
    "train_y = training_set.classes\n",
    "test_y = test_set.classes\n",
    "val_y = val_set.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8191a-37a0-47ba-a7d6-58c5dc39f775",
   "metadata": {},
   "source": [
    "***Class 0 is AI-images***     |     ***Class 1 is Real_images***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763297c9-1689-49ab-9fd2-558ba93ffcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing class lebel (name and number)\n",
    "\n",
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6365227-5cd9-43b8-8dcc-09ceecf22905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf1095-c2fd-4219-a729-0f0479c21e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the dimensional of the arrays (train_y, test_y, val_y) and their elements\n",
    "# All of them are one-dimensional \n",
    "\n",
    "train_y.shape,test_y.shape,val_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f44cf-317c-4a37-8425-be0362ed16a0",
   "metadata": {},
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead789f-f0dc-46bf-bf07-e79e48bb3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Model Building\n",
    "\n",
    "# import VGG-19\n",
    "IMAGE_SIZE = [224,224]\n",
    "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "#Do not train the pre-trained layers of VGG-19\n",
    "#freeze These Layers: This prevents them from being updated during future training rounds.\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ddf6f-482b-4a42-b87f-34e34eb97c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize the model \"by changing its last layer alone according to the number of classes \"2\" in our problem\"\n",
    "\n",
    "# fine tuning the model by flatten the last layer and adapt it for our problem\n",
    "x = Flatten()(vgg.output)\n",
    "\n",
    "#adding output layer.Softmax classifier is used as it is use for multi-class or binary classification\n",
    "# here 2 means binary classification, if 3 or 4 ... it is multi-class classification\n",
    "prediction = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7144117-6d49-44f7-b85e-3f40045e4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model after fine tuning the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a7d5a-234f-4598-8316-489070f56f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Compiling the model\n",
    "# The defualt model's labels are one-hot encoded \"need to be changed\" \n",
    "# Use sparse categorical cross-entropy as our loss function.\n",
    "# Use the best optimizer called adam optimizer as it decides the best learning rate on its own.\n",
    "\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer=\"adam\",\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe321af2-3e30-4228-b391-769296fe7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Fitting the model\n",
    "# importing Early stopping to avoid overfitting of model.\n",
    "# use early stopping to stop training the model any further if the validation loss suddenly starts increasing.\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0dae1-931b-4f59-ab74-aa4795091504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training (fit the model)\n",
    "\n",
    "history = model.fit(\n",
    "  train_x,\n",
    "  train_y,\n",
    "  validation_data=(val_x,val_y),\n",
    "  epochs=5,\n",
    "  callbacks=[early_stop],\n",
    "  batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66e023-b997-4736-b829-8a31dfb2dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the performance of our model on training and validation datasets,\n",
    "# with the help of accuracy and loss graphs:\n",
    "\n",
    "# accuracies\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig('vgg-acc-rps-1.png')\n",
    "plt.show()\n",
    "\n",
    "# loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig('vgg-loss-rps-1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd456770-f698-4e91-a9d7-c503a3722c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-4 : Model Evaluation\n",
    "# evaluating our model by testing it on the test dataset.\n",
    "\n",
    "model.evaluate(test_x,test_y,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5ba2d-82dd-45f7-81c8-47da356c45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model's efficiency,by observing its classification report and confusion matrix.\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "#predict\n",
    "y_pred=model.predict(test_x)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "\n",
    "#get classification report\n",
    "print(classification_report(y_pred,test_y))\n",
    "\n",
    "#get confusion matrix\n",
    "print(confusion_matrix(y_pred,test_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6b77a-a236-4dcf-92ca-d9070276ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the predicted labels and the corresponding original labels\n",
    "print(\"Predicted labels\\n\", y_pred)\n",
    "print(\"\\nOriginal labels\\n\", test_y)\n",
    "\n",
    "# Counting the mis-classified images\n",
    "mis_AI_images = 0\n",
    "mis_Real_images = 0\n",
    "\n",
    "# mis-classified images\n",
    "misclassified_images = []\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != test_y[i]:\n",
    "        if test_y[i] == 0:\n",
    "            mis_AI_images +=1\n",
    "        else:\n",
    "            mis_Real_images += 1\n",
    "        misclassified_images.append(x_test[i])\n",
    "            \n",
    "if mis_AI_images != 0 or mis_Real_images != 0:\n",
    "    print(\"\\nTesting the model : Out of \"+str(len(y_pred))+\" images , \"+ str(mis_AI_images) +\n",
    "          \" AI-images have been mis-classified as Real images, and \"+\n",
    "          str(mis_Real_images) +\" Real images have been mis-classified as AI-images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be306cd-8ea7-4201-a563-cc63e4873cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the images that the model misclassified\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#misclassified_images = np.array(misclassified_images)\n",
    "#misclassified_images = misclassified_images/255.0\n",
    "\n",
    "if len(misclassified_images) > 1:\n",
    "    for img in misclassified_images:\n",
    "        rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(rgb_image)\n",
    "       \n",
    "        try:\n",
    "        \n",
    "            display(image)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image file '{image_path}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef1834-6166-42a7-b8f8-09fdfb2323cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our train Model\n",
    "\n",
    "model.save('save/New_vgg19_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
