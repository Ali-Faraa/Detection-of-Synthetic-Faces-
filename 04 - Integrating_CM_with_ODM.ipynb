{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f59334f-c871-4975-9c25-38b3987ac90b",
   "metadata": {},
   "source": [
    "# Integrating_Yolov8_with_VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25746cb-9af8-4654-94de-cc97b386b820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1402e-0338-4f83-b419-7bf0ca14b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8ff0d-54c1-4eda-88f7-50485cd853bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model VGG19 \n",
    "from tensorflow import keras\n",
    "\n",
    "loaded_model = keras.models.load_model(\"../save/VGG19_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86666a-2c26-419e-b306-dac163a871c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG91_to_predict_single_image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load  image\n",
    "\n",
    "img = cv2.imread('../AI_High_Resolution/1.jpg')\n",
    "\n",
    "#img = cv2.imread('../Real_High_Resolution/Diverse-group-of-people.jpg')\n",
    "\n",
    "\n",
    "\n",
    "# Resize the image (assuming 224x224 input)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "\n",
    "# Convert to NumPy array and normalize (assuming BGR format)\n",
    "img = img.astype(np.float32) / 255.0\n",
    "\n",
    "# Reshape the image to add a batch dimension\n",
    "img_batch = np.expand_dims(img, axis=0)\n",
    "\n",
    "#predictions \n",
    "predictions = loaded_model.predict(img_batch)\n",
    "\n",
    "print(predictions)\n",
    "print(\"The probability of the image belonging to the AI-images class : \",predictions[0][0])\n",
    "print(\"The probability of the image belonging to the Real images class : \",predictions[0][1])\n",
    "\n",
    "#print(\"lebel/class : \",predicted_class_index)\n",
    "if predictions[0][0] > predictions[0][1]:\n",
    "    print(\"Al-generated image\")\n",
    "else:\n",
    "    print(\"Real image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136b2a4-1916-43c4-886e-50b94f94cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Yolo\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a trained model yolov8\n",
    "\n",
    "trained_model = YOLO(\"../save/YoloV8_Face_Detection_Model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb6c04-5a78-4a36-814b-5f4893ab7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "\n",
    "source_image = cv2.imread('../AI_High_Resolution/1.jpg')\n",
    "\n",
    "#source_image = cv2.imread('../Real_High_Resolution/Diverse-group-of-people.jpg')\n",
    "\n",
    "\n",
    "results = trained_model(source_image , conf = 0.70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a6bef-041b-47fb-b2bd-0bfb8300c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0]\n",
    "from PIL import Image\n",
    "Image.fromarray(result.plot()[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c80c5a-6b75-461e-a8a1-7f60df986ecb",
   "metadata": {},
   "source": [
    "# CODE OF PREDICTION \"CROPPING SQUARED BOUNDING BOX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e79a8-5a4c-4074-921b-e27c7e6b1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cropped_imgs = []\n",
    "\n",
    "# Extract bounding boxes\n",
    "boxes = results[0].boxes.xyxy.cpu().tolist()\n",
    "\n",
    "# Iterate through each bounding box\n",
    "for i, box in enumerate(boxes):\n",
    "    \n",
    "    x_min, y_min, x_max, y_max = map(int, box)  # Convert coordinates to integers for indexing\n",
    "\n",
    "    # Calculate the width and height of the bounding box\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "\n",
    "    # Determine the size of the square\n",
    "    side_length = max(width, height)\n",
    "\n",
    "    # Calculate the center of the bounding box\n",
    "    center_x = x_min + width // 2\n",
    "    center_y = y_min + height // 2\n",
    "\n",
    "    # Calculate the new square bounding box coordinates\n",
    "    new_x_min = center_x - side_length // 2\n",
    "    new_y_min = center_y - side_length // 2\n",
    "    new_x_max = center_x + side_length // 2\n",
    "    new_y_max = center_y + side_length // 2\n",
    "\n",
    "    # Ensure the coordinates are within the image boundaries\n",
    "    new_x_min = max(0, new_x_min)\n",
    "    new_y_min = max(0, new_y_min)\n",
    "    new_x_max = min(source_image.shape[1], new_x_max)\n",
    "    new_y_max = min(source_image.shape[0], new_y_max)\n",
    "\n",
    "    # Crop the image\n",
    "    cropped_img = source_image[new_y_min:new_y_max, new_x_min:new_x_max]\n",
    "    #print ( new_y_min, new_y_max, new_x_min , new_x_max)\n",
    "    \n",
    "    #######################\n",
    "    #x1, y1, x2, y2 = map(int, box)  # Convert coordinates to integers for indexing\n",
    "    #print ( x1, y1, x2, y2)\n",
    "    # Crop the object using the bounding box coordinates\n",
    "    #cropped_img = source_image[y1:y2, x1:x2]\n",
    "\n",
    "    # Save the cropped image \n",
    "    cv2.imwrite(f'cropped_img{i}.jpg', cropped_img)\n",
    "    \n",
    "        \n",
    "    # Resize the image (VGG19 --- 224x224 input)\n",
    "    img = cv2.resize(cropped_img,(224,224))\n",
    "\n",
    "    cropped_imgs.append(img)\n",
    "        \n",
    "print(\"No. of faces : \",len(cropped_imgs))        \n",
    "# Convert to NumPy array and normalize \n",
    "cropped_imgs = np.array(cropped_imgs)\n",
    "\n",
    "cropped_imgs = cropped_imgs/255.0\n",
    "\n",
    "# Reshape the image to add a batch dimension\n",
    "#img_batch = np.expand_dims(img, axis=0)\n",
    "#print(img_batch.shape)\n",
    "\n",
    "\n",
    "predictions = loaded_model.predict(cropped_imgs)\n",
    "\n",
    "print(\"predictions probabilities:\\n\",predictions)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictions:\n",
    "    \n",
    "    print('\\n',prediction)\n",
    "    print(\"The probability of the image belonging to the AI-images class : \",prediction[0])\n",
    "    print(\"The probability of the image belonging to the Real images class : \",prediction[1])\n",
    "\n",
    "    # Find the class with the highest probability\n",
    "    # np.argmax returns the index/indices of the maximum value(s) along an axis. \n",
    "    # For example, if we have an array [1, 3, 2, 4], np.argmax would return 3 (index) because 4 is the highest value.\n",
    "    # predicted_class_index = np.argmax(predictions[0])  # Access the first element (your image)\n",
    "\n",
    "    \n",
    "    if prediction[0] > prediction[1]:\n",
    "        print(\"lebel/class : 0 \",)\n",
    "        print(\"Al-generated image\")\n",
    "    else:\n",
    "        print(\"lebel/class : 1 \")\n",
    "        print(\"Real image\")\n",
    "    image_path = f'cropped_img{i}.jpg'\n",
    "    i +=1\n",
    "    try:\n",
    "        # Open the image using PIL\n",
    "        image = Image.open(image_path)\n",
    "        display(image)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file '{image_path}' not found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c356be-cfcf-470f-a63f-50c5b385f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
